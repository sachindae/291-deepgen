{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1667178827248,
     "user": {
      "displayName": "Eunji Song",
      "userId": "02630850563491596195"
     },
     "user_tz": 420
    },
    "id": "nj3UiunCO1p9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import midi_statistics\n",
    "import utils\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from models import Diffusion #, UNet_1D\n",
    "from dilated import DiffWave, DiffWave_wText\n",
    "from modules import UNet\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import MIDIDataset \n",
    "from torchtext.data.metrics import bleu_score\n",
    "import random\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667178827249,
     "user": {
      "displayName": "Eunji Song",
      "userId": "02630850563491596195"
     },
     "user_tz": 420
    },
    "id": "f6vkexZjO1p-"
   },
   "outputs": [],
   "source": [
    "\n",
    "syll_model_path = './enc_models/syllEncoding_20190419.bin'\n",
    "word_model_path = './enc_models/wordLevelEncoder_20190419.bin'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1700,
     "status": "ok",
     "timestamp": 1667178828947,
     "user": {
      "displayName": "Eunji Song",
      "userId": "02630850563491596195"
     },
     "user_tz": 420
    },
    "id": "jVgpNt6HO1p-"
   },
   "outputs": [],
   "source": [
    "\n",
    "syllModel = Word2Vec.load(syll_model_path)\n",
    "wordModel = Word2Vec.load(word_model_path)\n",
    "\n",
    "'''\n",
    "lyrics = [['Then','Then'],['the','the'],['rain','rainstorm'],['storm','rainstorm'],['came','came'],\n",
    "          ['ov','over'],['er','over'],['me','me'],['and','and'],['i','i'],['felt','felt'],['my','my'],\n",
    "          ['spi','spirit'],['rit','spirit'],['break','break']]\n",
    "lyrics = [['E','Everywhere'],['very','Everywhere'],['where','Everywhere'],['I','I'],['look','look'],\n",
    "         ['I','I'],['found','found'],['you','you'],['look','looking'],['king','looking'],['back','back']]\n",
    "\n",
    "lyrics = [['Must','Must'],['have','have'],['been','been'],['love','love'],\n",
    "          ['but','but'],['its','its'],['o','over'],['ver','over'],['now','now'],['lay','lay'],['a','a'],\n",
    "          ['whis','whisper'],['per','whisper'],['on','on'],['my','my'],['pil','pillow'],['low','pillow']]\n",
    "lyrics = [['You','You'],['turn','turn'],['my','my'],['nights','nights'],\n",
    "          ['in','into'],['to','into'],['days','days'],['Lead','Lead'],['me','me'],['mys','mysterious'],['te','mysterious'],\n",
    "          ['ri','mysterious'],['ous','mysterious'],['ways','ways']]\n",
    "'''\n",
    "# test data (0~2)\n",
    "#lyrics = [['Peo', 'People'], ['ple', 'People'], ['get', 'get'], ['rea', 'ready'], ['dy', 'ready'], ['a', 'a'], ['train', 'train'], ['a', 'a'], ['you', 'you'], ['need', 'need'], ['no', 'no'], ['bag', 'baggage'], ['gage', 'baggage'], ['you', 'you'], ['just', 'just'], ['get', 'get'], ['on', 'on'], ['board', 'board'], ['you', 'you'], ['need', 'need']]\n",
    "#lyrics = [['hear', 'hear'], ['the', 'the'], ['die', 'diesels'], ['sels', 'diesels'], ['need', 'need'], ['no', 'no'], ['tic', 'ticket'], ['ket', 'ticket'], ['you', 'you'], ['just', 'just'], ['thank', 'thank'], ['the', 'the'], ['Lord', 'Lord'], ['so', 'so'], ['peo', 'people'], ['ple', 'people'], ['get', 'get'], ['rea', 'ready'], ['dy', 'ready'], ['coast', 'coast']]\n",
    "#lyrics = [['gon', 'gonna'], ['na', 'gonna'], ['be', 'be'], ['a', 'a'], ['migh', 'mighty'], ['ty', 'mighty'], ['king', 'king'], ['So', 'So'], ['en', 'enemies'], ['e', 'enemies'], ['mies', 'enemies'], ['ZazuWell', 'ZazuWell'], ['nev', 'never'], ['er', 'never'], ['seen', 'seen'], ['a', 'a'], ['king', 'king'], ['of', 'of'], ['beasts', 'beasts'], ['With', 'With']]\n",
    "\n",
    "lyrics_list = [[['Peo', 'People'], ['ple', 'People'], ['get', 'get'], ['rea', 'ready'], ['dy', 'ready'], ['a', 'a'], ['train', 'train'], ['a', 'a'], ['you', 'you'], ['need', 'need'], ['no', 'no'], ['bag', 'baggage'], ['gage', 'baggage'], ['you', 'you'], ['just', 'just'], ['get', 'get'], ['on', 'on'], ['board', 'board'], ['you', 'you'], ['need', 'need']],\n",
    "[['hear', 'hear'], ['the', 'the'], ['die', 'diesels'], ['sels', 'diesels'], ['need', 'need'], ['no', 'no'], ['tic', 'ticket'], ['ket', 'ticket'], ['you', 'you'], ['just', 'just'], ['thank', 'thank'], ['the', 'the'], ['Lord', 'Lord'], ['so', 'so'], ['peo', 'people'], ['ple', 'people'], ['get', 'get'], ['rea', 'ready'], ['dy', 'ready'], ['coast', 'coast']],\n",
    "[['gon', 'gonna'], ['na', 'gonna'], ['be', 'be'], ['a', 'a'], ['migh', 'mighty'], ['ty', 'mighty'], ['king', 'king'], ['So', 'So'], ['en', 'enemies'], ['e', 'enemies'], ['mies', 'enemies'], ['ZazuWell', 'ZazuWell'], ['nev', 'never'], ['er', 'never'], ['seen', 'seen'], ['a', 'a'], ['king', 'king'], ['of', 'of'], ['beasts', 'beasts'], ['With', 'With']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  11149  songs, Validation set:  1051  songs, Test set:  1051  songs.\n",
      "Num samples: 11149\n",
      "Num samples: 1051\n",
      "Num samples: 1051\n"
     ]
    }
   ],
   "source": [
    "train = np.load('./data/processed_dataset_matrices/train_data_matrix.npy')\n",
    "validate = np.load('./data/processed_dataset_matrices/valid_data_matrix.npy')\n",
    "test = np.load('./data/processed_dataset_matrices/test_data_matrix.npy')\n",
    "\n",
    "print(\"Training set: \", np.shape(train)[0], \" songs, Validation set: \", np.shape(validate)[0], \" songs, \"\n",
    "      \"Test set: \", np.shape(test)[0], \" songs.\")\n",
    "\n",
    "NUM_MIDI_FEATURES = 3\n",
    "NUM_SYLLABLE_FEATURES = 20\n",
    "SONGLENGTH = 20\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Load datasets\n",
    "dataset_train = MIDIDataset(train, NUM_MIDI_FEATURES, SONGLENGTH, NUM_SYLLABLE_FEATURES)\n",
    "dataset_valid = MIDIDataset(validate, NUM_MIDI_FEATURES, SONGLENGTH, NUM_SYLLABLE_FEATURES)\n",
    "dataset_test = MIDIDataset(test, NUM_MIDI_FEATURES, SONGLENGTH, NUM_SYLLABLE_FEATURES)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_valid, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_encode(lyr_list):\n",
    "    enc_lyr = []\n",
    "    \n",
    "    for lyrics in lyr_list:\n",
    "        length_song = len(lyrics)\n",
    "        cond = []\n",
    "        \n",
    "        for i in range(20):\n",
    "            if i < length_song:\n",
    "                syll2Vec = syllModel.wv[lyrics[i][0]]\n",
    "                word2Vec = wordModel.wv[lyrics[i][1]]\n",
    "                cond.append(np.concatenate((syll2Vec,word2Vec)))\n",
    "            else:\n",
    "                cond.append(np.concatenate((syll2Vec,word2Vec)))\n",
    "        \n",
    "        \n",
    "        flattened_cond = []\n",
    "        for x in cond:\n",
    "            for y in x:\n",
    "                flattened_cond.append(y)\n",
    "        enc_lyr.append(flattened_cond)\n",
    "    return np.array(enc_lyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_to_sentence(lyr):\n",
    "    # input: [['Then','Then'],['the','the'],['rain','rainstorm'],['storm','rainstorm'],['came','came'],\n",
    "    #          ['ov','over'],['er','over'],['me','me'],['and','and'],['i','i'],['felt','felt'],['my','my'],\n",
    "    #          ['spi','spirit'],['rit','spirit'],['break','break']],\n",
    "    # output: Then the rainstorm came over me and i felt my spirit break\n",
    "    sentence = \"\"\n",
    "    for w, s in lyr:\n",
    "        sentence += w + \" \"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_music_baseline(lyr_data, length_song):\n",
    "    model_path = './saved_gan_models/saved_model_best_overall_mmd'\n",
    "\n",
    "    with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
    "        tf.compat.v1.saved_model.loader.load(sess, [], model_path)\n",
    "        graph = tf.compat.v1.get_default_graph()\n",
    "        keep_prob = graph.get_tensor_by_name(\"model/keep_prob:0\")\n",
    "        input_metadata = graph.get_tensor_by_name(\"model/input_metadata:0\")\n",
    "        input_songdata = graph.get_tensor_by_name(\"model/input_data:0\")\n",
    "        output_midi = graph.get_tensor_by_name(\"output_midi:0\")\n",
    "\n",
    "        for i, fc in enumerate(lyr_data):\n",
    "            feed_dict = {}\n",
    "            feed_dict[keep_prob.name] = 1.0\n",
    "            condition = []\n",
    "            feed_dict[input_metadata.name] = condition\n",
    "            feed_dict[input_songdata.name] = np.random.uniform(size=(1, 20, 3))\n",
    "            condition.append(np.split(np.asarray(fc), 20))\n",
    "            feed_dict[input_metadata.name] = condition\n",
    "            generated_features = sess.run(output_midi, feed_dict)\n",
    "            sample = [x[0, :] for x in generated_features]\n",
    "            sample = midi_statistics.tune_song(utils.discretize(sample))\n",
    "            midi_pattern = utils.create_midi_pattern_from_discretized_data(sample[0:length_song])\n",
    "            destination = \"poster/model1/model1\"+str(i)+\".mid\"\n",
    "            midi_pattern.write(destination)\n",
    "\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_music_om(lyr_data):\n",
    "    our_model_path = 'saved_models/saved_model'\n",
    "    lr = 9e-4\n",
    "    diffusion = Diffusion()\n",
    "    model = DiffWave_wText(device=device).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    mse = torch.nn.MSELoss()\n",
    "\n",
    "    state_dict = torch.load(our_model_path)\n",
    "    model.load_state_dict(state_dict['model'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer'])\n",
    "    print('Model loaded!', our_model_path)\n",
    "    \n",
    "    #sample_lyrics = torch.Tensor(lyrics_encode(lyrics_list)).to(device)\n",
    "    sample_lyrics = torch.Tensor(lyr_data).to(device)\n",
    "    #sampled_melodies = diffusion.sample_1d_wText(model, syllable_embs, n=syllable_embs.shape[0]).cpu().detach()\n",
    "    sampled_melodies = diffusion.sample_1d_wText(model, sample_lyrics, n=sample_lyrics.shape[0]).cpu().detach()\n",
    "    for i,sampled_melody in enumerate(sampled_melodies):\n",
    "        sampled_melody = sampled_melody.transpose(1, 0).numpy() # -> [melody len, 3]\n",
    "        denormed_melody = dataset_test.denormalize2(sampled_melody)\n",
    "\n",
    "        #denormed_melody = np.concatenate((denormed_melody, np.ones(denormed_melody.shape), np.zeros(denormed_melody.shape)), axis=1)\n",
    "        denormed_melody = dataset_test.discretize(denormed_melody)\n",
    "        tuned_melody = midi_statistics.tune_song(denormed_melody)\n",
    "        midi_melody_tuned = dataset_test.create_midi_pattern_from_discretized_data(tuned_melody)\n",
    "        destination = \"poster/model2/model2\"+str(i)+\".mid\"\n",
    "        midi_melody_tuned.write(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17174,
     "status": "ok",
     "timestamp": 1667178846120,
     "user": {
      "displayName": "Eunji Song",
      "userId": "02630850563491596195"
     },
     "user_tz": 420
    },
    "id": "yaA38HuhO1p_",
    "outputId": "d76acec6-cc64-4eb6-ef45-187573e39429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_gan_models/saved_model_best_overall_mmd\\variables\\variables\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "make_music_baseline(test[:,60:], SONGLENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667178846120,
     "user": {
      "displayName": "Eunji Song",
      "userId": "02630850563491596195"
     },
     "user_tz": 420
    },
    "id": "dH4PmtWXO1qA",
    "outputId": "d572ed02-6f02-44a4-f77a-299eba1818de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded! saved_models/saved_model\n"
     ]
    }
   ],
   "source": [
    "make_music_om(test[:,60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1667178846120,
     "user": {
      "displayName": "Eunji Song",
      "userId": "02630850563491596195"
     },
     "user_tz": 420
    },
    "id": "NrnCl0pG1HE_"
   },
   "outputs": [],
   "source": [
    "midis = test[:,:60]\n",
    "syls = test[:,60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, midi in enumerate(midis):\n",
    "    midi = midi.reshape(20,3)\n",
    "    melody = dataset_test.create_midi_pattern_from_discretized_data(midi)\n",
    "    destination = \"poster/gt/gt\"+str(i)+\".mid\"\n",
    "    melody.write(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
